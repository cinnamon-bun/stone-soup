// Generated by dts-bundle-generator v5.9.0

/// <reference types="heap" />
/// <reference types="node" />

import { Lock } from 'concurrency-friends';
import { Simplebus, Superbus } from 'superbus';
import { SuperbusMap } from 'superbus-map';

export declare type AuthorAddress = string;
export declare type AuthorShortname = string;
export declare type WorkspaceAddress = string;
export declare type WorkspaceName = string;
export declare type Path = string;
export declare type Signature = string;
export declare type Timestamp = number;
export declare type LocalIndex = number;
export declare type Base32String = string;
export declare type FormatName = string;
export interface AuthorKeypair {
	address: AuthorAddress;
	secret: string;
}
export declare type ParsedAddress = {
	address: AuthorAddress;
	name: AuthorShortname;
	pubkey: Base32String;
};
export interface Doc {
	format: string;
	author: AuthorAddress;
	content: string;
	contentHash: string;
	deleteAfter: number | null;
	path: Path;
	signature: Signature;
	timestamp: Timestamp;
	workspace: WorkspaceAddress;
	_localIndex?: LocalIndex;
}
export interface DocToSet {
	format: string;
	path: Path;
	content: string;
	timestamp?: number;
	deleteAfter?: number | null;
}
/** Generic top-level error class that other Earthstar errors inherit from. */
export declare class EarthstarError extends Error {
	constructor(message?: string);
}
/** Validation failed on a document, workspace address, author address, etc. */
export declare class ValidationError extends EarthstarError {
	constructor(message?: string);
}
/** An IStorageAsync or IStorageDriverAsync was used after close() was called on it. */
export declare class StorageIsClosedError extends EarthstarError {
	constructor(message?: string);
}
/** A QueryFollower was used after close() was called on it. */
export declare class QueryFollowerIsClosedError extends EarthstarError {
	constructor(message?: string);
}
export declare class NotFoundError extends EarthstarError {
	constructor(message?: string);
}
/** A pub URL is bad or the network is down */
export declare class NetworkError extends EarthstarError {
	constructor(message?: string);
}
export declare class TimeoutError extends EarthstarError {
	constructor(message?: string);
}
/** A pub won't accept writes */
export declare class ConnectionRefusedError extends EarthstarError {
	constructor(message?: string);
}
export declare class NotImplementedError extends EarthstarError {
	constructor(message?: string);
}
/** Check if any value is a subclass of EarthstarError (return true) or not (return false) */
export declare let isErr: <T>(x: Error | T) => x is EarthstarError;
/** Check if any value is a subclass of EarthstarError (return false) or not (return true) */
export declare let notErr: <T>(x: Error | T) => x is T;
export declare let assembleAuthorAddress: (name: AuthorShortname, encodedPubkey: Base32String) => AuthorAddress;
export declare let assembleWorkspaceAddress: (name: WorkspaceName, encodedPubkey: Base32String) => WorkspaceAddress;
export declare let checkAuthorIsValid: (addr: AuthorAddress) => true | ValidationError;
export declare let checkWorkspaceIsValid: (addr: WorkspaceAddress) => true | ValidationError;
/** Parse an author address into its parts. */
export declare let parseAuthorAddress: (address: AuthorAddress) => ParsedAddress | ValidationError;
/** Parse a workspace address into its parts. */
export declare let parseWorkspaceAddress: (address: WorkspaceAddress) => ParsedAddress | ValidationError;
export interface ParseAddressOpts {
	sigil: string;
	separator: string;
	minNameLength: number;
	maxNameLength: number;
	minPubkeyLength: number;
	maxPubkeyLength: number;
	allowedNameCharacters: string;
	allowedPubkeyCharacters: string;
	pubkeyMustStartWithB: boolean;
}
export declare let parseAddress: (address: string, opts: ParseAddressOpts) => ParsedAddress | ValidationError;
export declare let onlyHasChars: (str: string, allowedChars: string) => boolean;
export declare let isOnlyPrintableAscii: (s: string) => boolean;
export declare let isDigit: (ch: string) => boolean;
export declare const alphaLower = "abcdefghijklmnopqrstuvwxyz";
export declare const alphaUpper: string;
export declare const digits = "0123456789";
export declare const b32chars: string;
export declare const authorNameChars: string;
export declare const authorKeyChars: string;
export declare const authorAddressChars: string;
export declare const workspaceNameChars: string;
export declare const workspaceKeyChars: string;
export declare const workspaceAddressChars: string;
export declare const pathPunctuation = "/'()-._~!$&+,:=@%";
export declare const pathChars: string;
export declare type Ob = {
	[k: string]: any;
};
export declare type Checker = (x: any) => null | string;
export declare type CheckerSchema = {
	[k: string]: Checker;
};
export declare let isPlainObject: (obj: any) => obj is Ob;
export declare let checkIsPlainObject: Checker;
export declare let checkLiteral: (val: any) => Checker;
export interface CheckStringOpts {
	optional?: boolean;
	minLen?: number;
	maxLen?: number;
	len?: number;
	allowedChars?: string;
}
export declare let checkString: (opts?: CheckStringOpts) => Checker;
export interface CheckIntOpts {
	optional?: boolean;
	nullable?: boolean;
	min?: number;
	max?: number;
}
export declare let checkInt: (opts?: CheckIntOpts) => Checker;
export interface CheckObjOpts {
	allowLiteralUndefined?: boolean;
	allowExtraKeys?: boolean;
	objSchema?: CheckerSchema;
}
export declare let checkObj: (opts?: CheckObjOpts) => Checker;
/**
 * Encode uint8array bytes to base32 string
 */
export declare let base32BytesToString: (bytes: Uint8Array) => Base32String;
/**
* Decode base32 string to a uint8array of bytes.  Throw a ValidationError if the string is bad.
*/
export declare let base32StringToBytes: (str: Base32String) => Uint8Array;
export interface KeypairBytes {
	pubkey: Uint8Array;
	secret: Uint8Array;
}
/**
 * The higher-level crypto functions.
 * These all handle base32-encoded strings.
 */
export interface ICrypto {
	sha256base32(input: string | Uint8Array): Base32String;
	generateAuthorKeypair(name: string): AuthorKeypair | ValidationError;
	sign(keypair: AuthorKeypair, msg: string | Uint8Array): Base32String | ValidationError;
	verify(authorAddress: AuthorAddress, sig: Base32String, msg: string | Uint8Array): boolean;
	checkAuthorKeypairIsValid(keypair: AuthorKeypair): true | ValidationError;
}
/**
 * These are the basic crypto primitives we need.
 * There are several implementations which provide this interface,
 * e.g. native Node, Chloride, etc.
 * These all handle Uint8Arrays (bytes)
 */
export interface ICryptoDriver {
	sha256(input: string | Uint8Array): Uint8Array;
	generateKeypairBytes(): KeypairBytes;
	sign(keypairBytes: KeypairBytes, msg: string | Uint8Array): Uint8Array;
	verify(publicKey: Uint8Array, sig: Uint8Array, msg: string | Uint8Array): boolean;
}
/**
 * A verison of the ILowLevelCrypto interface backed by TweetNaCl.
 * Works in the browser.
 */
export declare const CryptoDriverTweetnacl: ICryptoDriver;
export declare const Crypto: ICrypto;
export declare let GlobalCryptoDriver: ICryptoDriver;
export declare let setGlobalCryptoDriver: (driver: ICryptoDriver) => void;
/** Combine a shortname with a raw KeypairBytes to make an AuthorKeypair */
export declare let encodeAuthorKeypairToStrings: (shortname: AuthorShortname, pair: KeypairBytes) => AuthorKeypair;
/** Convert an AuthorKeypair back into a raw KeypairBytes for use in crypto operations. */
export declare let decodeAuthorKeypairToBytes: (pair: AuthorKeypair) => KeypairBytes | ValidationError;
/**
 * Validators are each responsible for one document format such as "es.4".
 * They are used by Storage instances to
 * * check if documents are valid before accepting them
 * * sign new documents
 *
 * According to the rules of Earthstar: documents are validated statelessly,
 * one document at a time, without knowing about any other documents
 * or what's in the Storage.
 *
 */
export interface IFormatValidator {
	/** The string name of the format, like "es.4" */
	format: FormatName;
	/** Deterministic hash of this version of the document */
	hashDocument(doc: Doc): Base32String | ValidationError;
	/**
	 * Add an author signature to the document.
	 * The input document needs a signature field to satisfy Typescript, but
	 * it will be overwritten here, so you may as well just set signature: '' on the input.
	 * Return a copy of the original document with the signature field changed, or return a ValidationError.
	 */
	signDocument(keypair: AuthorKeypair, doc: Doc): Doc | ValidationError;
	/**
	 * Return a copy of the doc without extra fields, plus the extra fields
	 * as a separate object.
	 * If the input is not a plain javascript object, return a ValidationError.
	 * This should be run before checkDocumentIsValid.  The output doc will be
	 * more likely to be valid once the extra fields have been removed.
	 */
	removeExtraFields(doc: Doc): {
		doc: Doc;
		extras: Record<string, any>;
	} | ValidationError;
	/**
	 * This calls all the more detailed functions which start with underscores.
	 * Returns true if the document is ok.
	 */
	checkDocumentIsValid(doc: Doc, now?: number): true | ValidationError;
	_checkBasicDocumentValidity(doc: Doc): true | ValidationError;
	_checkAuthorCanWriteToPath(author: AuthorAddress, path: Path): true | ValidationError;
	_checkTimestampIsOk(timestamp: number, deleteAfter: number | null, now: number): true | ValidationError;
	_checkPathIsValid(path: Path, deleteAfter?: number | null): true | ValidationError;
	_checkAuthorSignatureIsValid(doc: Doc): true | ValidationError;
	_checkContentMatchesHash(content: string, contentHash: Base32String): true | ValidationError;
}
export declare const FormatValidatorEs4: IFormatValidator;
export interface QueryFilter {
	path?: Path;
	pathStartsWith?: string;
	pathEndsWith?: string;
	author?: AuthorAddress;
	timestamp?: Timestamp;
	timestampGt?: Timestamp;
	timestampLt?: Timestamp;
	contentLength?: number;
	contentLengthGt?: number;
	contentLengthLt?: number;
}
export declare type HistoryMode = "latest" | "all";
export interface Query {
	historyMode?: HistoryMode;
	orderBy?: "path ASC" | "path DESC" | "localIndex ASC" | "localIndex DESC";
	startAfter?: {
		localIndex?: number;
		path?: string;
	};
	filter?: QueryFilter;
	limit?: number;
}
export declare let DEFAULT_QUERY: Query;
export declare type StorageId = string;
export declare type StorageBusChannel = "ingest" | // 'write|/some/path.txt'  // note that write errors and no-ops are also sent here
"willClose" | "didClose";
export interface QueryResult {
	docs: Doc[];
	maxLocalIndexBefore: number;
	maxLocalIndexAfter: number;
	maxLocalIndexInResult: number;
}
export interface IngestEventFailure {
	kind: "failure";
	reason: "write_error" | "invalid_document";
	maxLocalIndex: number;
	err: Error | null;
}
export interface IngestEventNothingHappened {
	kind: "nothing_happened";
	reason: "obsolete_from_same_author" | "already_had_it";
	maxLocalIndex: number;
	doc: Doc;
}
export interface IngestEventSuccess {
	kind: "success";
	maxLocalIndex: number;
	doc: Doc;
	docIsLatest: boolean;
	prevDocFromSameAuthor: Doc | null;
	prevLatestDoc: Doc | null;
}
export interface DocAlreadyExists {
	kind: "existing";
	maxLocalIndex: number;
	doc: Doc;
}
export interface StorageEventWillClose {
	kind: "willClose";
	maxLocalIndex: number;
}
export interface StorageEventDidClose {
	kind: "didClose";
}
export interface QueryFollowerDidClose {
	kind: "queryFollowerDidClose";
}
export interface IdleEvent {
	kind: "idle";
}
export declare type IngestEvent = IngestEventFailure | IngestEventNothingHappened | IngestEventSuccess;
export declare type LiveQueryEvent = DocAlreadyExists | // catching up...
IdleEvent | // waiting for an ingest to happen...
IngestEvent | // an ingest happened
StorageEventWillClose | StorageEventDidClose | QueryFollowerDidClose;
export interface IStorageAsyncConfigStorage {
	getConfig(key: string): Promise<string | undefined>;
	setConfig(key: string, value: string): Promise<void>;
	listConfigKeys(): Promise<string[]>;
	deleteConfig(key: string): Promise<boolean>;
}
export interface IStorageAsync extends IStorageAsyncConfigStorage {
	storageId: StorageId;
	workspace: WorkspaceAddress;
	formatValidator: IFormatValidator;
	storageDriver: IStorageDriverAsync;
	bus: Superbus<StorageBusChannel>;
	isClosed(): boolean;
	/**
	 * close()
	 *   * send StorageWillClose events and wait for event receivers to finish blocking.
	 *   * close the IStorage
	 *   * close the IStorageDriver and possibly erase it
	 *   * send StorageDidClose events and do not wait for event receivers.
	 *
	 * Any function called after the storage is closed will throw a StorageIsClosedError,
	 *  except isClosed() is always allowed.
	 *
	 * You cannot call close() if the storage is already closed (it will throw a StorageIsClosedError).
	 *
	 * close() can happen while set() or ingest() are waiting for locks or have pending transactions.
	 * In that case, the pending operations will fail and throw a storageIsClosed.
	 *
	 * If erase is true, actually delete and forget the local data (remove files, etc).
	 * Erase defaults to false if not provided.
	 */
	close(erase: boolean): Promise<void>;
	getMaxLocalIndex(): number;
	getDocsAfterLocalIndex(historyMode: HistoryMode, startAfter: LocalIndex, limit?: number): Promise<Doc[]>;
	getAllDocs(): Promise<Doc[]>;
	getLatestDocs(): Promise<Doc[]>;
	getAllDocsAtPath(path: Path): Promise<Doc[]>;
	getLatestDocAtPath(path: Path): Promise<Doc | undefined>;
	queryDocs(query?: Query): Promise<Doc[]>;
	set(keypair: AuthorKeypair, docToSet: DocToSet): Promise<IngestEvent>;
	ingest(doc: Doc): Promise<IngestEvent>;
	overwriteAllDocsByAuthor(keypair: AuthorKeypair): Promise<number | ValidationError>;
}
/**
 * A storageDriver provides low-level access to actual storage and is used by
 * IStorageAsync to actually load and save data.
 * StorageDrivers are not meant to be used directly by users; let the IStorageAsync
 * talk to it for you.
 */
export interface IStorageDriverAsync extends IStorageAsyncConfigStorage {
	workspace: WorkspaceAddress;
	isClosed(): boolean;
	/**
	 * Close the storageDriver.
	 * The Storage will call this.
	 * You cannot call close() if the storage is already closed (it will throw a StorageIsClosedError).
	 * If erase, actually delete and forget data locally.
	 * Erase defaults to false if not provided.
	 */
	close(erase: boolean): Promise<void>;
	getMaxLocalIndex(): number;
	queryDocs(query: Query): Promise<Doc[]>;
	upsert(doc: Doc): Promise<Doc>;
}
export declare type PeerId = string;
export interface IPeer {
	peerId: PeerId;
	hasWorkspace(workspace: WorkspaceAddress): boolean;
	workspaces(): WorkspaceAddress[];
	storages(): IStorageAsync[];
	size(): number;
	getStorage(ws: WorkspaceAddress): IStorageAsync | undefined;
	addStorage(storage: IStorageAsync): Promise<void>;
	removeStorageByWorkspace(workspace: WorkspaceAddress): Promise<void>;
	removeStorage(storage: IStorageAsync): Promise<void>;
}
/**
 * API endpoints follow some similar patterns:
 *
 * ## Do, Serve, Handle
 *
 *   - Client always initiates contact.
 *   - client_do_thing(thing_request) => void -- handles all the following calls:
 *   -     client asks for server.serve_thing(thing_request) => thing_response
 *   -     client.handle_thing(thing_response) => newState
 *   -     client.setState(newState)
 *
 *    FUNCTION             DATA TYPE
 *
 *                         x_request
 *    client.do_x
 *      server.serve_x
 *                         x_response
 *      client.handle_x
 *                         Partial<PeerClientState>
 *
 * ## Do, Serve, Process
 *
 * This is used when the client needs to perform some side-effects besides just
 * updating its own client state.  For example, ingesting docs.  It also lets
 * the overall return value of process_x and do_x be something more useful,
 * like the number of docs ingested.
 *
 *   - client_do_thing(thing_request) => ? -- handles all the following calls:
 *   -     client asks for server.serve_thing(thing_request) => thing_response
 *   -     client.process_thing(thing_response) => ?
 *
 *    FUNCTION             DATA TYPE
 *
 *                         x_request
 *    client.do_x
 *      server.serve_x
 *                         x_response
 *      client.process_x
 *                         ?
 */
export declare let saltAndHashWorkspace: (salt: string, workspace: WorkspaceAddress) => string;
export interface SaltyHandshake_Request {
}
export interface SaltyHandshake_Response {
	serverPeerId: PeerId;
	salt: string;
	saltedWorkspaces: string[];
}
export interface AllWorkspaceStates_Request {
	commonWorkspaces: WorkspaceAddress[];
}
export declare type AllWorkspaceStates_Response = {
	serverPeerId: PeerId;
	workspaceStatesFromServer: Record<WorkspaceAddress, WorkspaceStateFromServer>;
};
export declare type AllWorkspaceStates_Outcome = Record<WorkspaceAddress, WorkspaceState>;
export interface WorkspaceQuery_Request {
	workspace: WorkspaceAddress;
	storageId: StorageId;
	query: Query;
}
export interface WorkspaceQuery_Response {
	workspace: WorkspaceAddress;
	storageId: StorageId;
	serverMaxLocalIndexOverall: number;
	docs: Doc[];
}
export interface PeerClientState {
	serverPeerId: PeerId | null;
	commonWorkspaces: WorkspaceAddress[] | null;
	workspaceStates: Record<WorkspaceAddress, WorkspaceState>;
	lastSeenAt: number | null;
}
export interface WorkspaceStateFromServer {
	workspace: WorkspaceAddress;
	serverStorageId: StorageId;
	serverMaxLocalIndexOverall: number;
}
export interface WorkspaceState {
	workspace: WorkspaceAddress;
	serverStorageId: StorageId;
	serverMaxLocalIndexOverall: number;
	serverMaxLocalIndexSoFar: number;
	clientStorageId: StorageId;
	clientMaxLocalIndexOverall: number;
	clientMaxLocalIndexSoFar: number;
	lastSeenAt: number;
}
export declare let initialPeerClientState: PeerClientState;
export interface IPeerClient {
	setState(newState: Partial<PeerClientState>): Promise<void>;
	do_getServerPeerId(): Promise<PeerId>;
	do_saltyHandshake(): Promise<void>;
	handle_saltyHandshake(response: SaltyHandshake_Response): Promise<Partial<PeerClientState>>;
	do_allWorkspaceStates(): Promise<void>;
	handle_allWorkspaceStates(request: AllWorkspaceStates_Request, response: AllWorkspaceStates_Response): Promise<Partial<PeerClientState>>;
	do_workspaceQuery(request: WorkspaceQuery_Request): Promise<number>;
	process_workspaceQuery(response: WorkspaceQuery_Response): Promise<number>;
}
export interface IPeerServer {
	serve_peerId(): Promise<PeerId>;
	serve_saltyHandshake(request: SaltyHandshake_Request): Promise<SaltyHandshake_Response>;
	serve_allWorkspaceStates(request: AllWorkspaceStates_Request): Promise<AllWorkspaceStates_Response>;
	serve_workspaceQuery(request: WorkspaceQuery_Request): Promise<WorkspaceQuery_Response>;
}
export declare class PeerClient implements IPeerClient {
	peer: IPeer;
	server: IPeerServer;
	state: PeerClientState;
	constructor(peer: IPeer, server: IPeerServer);
	setState(newState: Partial<PeerClientState>): Promise<void>;
	do_getServerPeerId(): Promise<PeerId>;
	do_saltyHandshake(): Promise<void>;
	handle_saltyHandshake(response: SaltyHandshake_Response): Promise<Partial<PeerClientState>>;
	do_allWorkspaceStates(): Promise<void>;
	handle_allWorkspaceStates(request: AllWorkspaceStates_Request, response: AllWorkspaceStates_Response): Promise<Partial<PeerClientState>>;
	do_workspaceQuery(request: WorkspaceQuery_Request): Promise<number>;
	process_workspaceQuery(response: WorkspaceQuery_Response): Promise<number>;
}
export declare class PeerServer implements IPeerServer {
	peer: IPeer;
	constructor(peer: IPeer);
	serve_peerId(): Promise<PeerId>;
	serve_saltyHandshake(request: SaltyHandshake_Request): Promise<SaltyHandshake_Response>;
	serve_allWorkspaceStates(request: AllWorkspaceStates_Request): Promise<AllWorkspaceStates_Response>;
	serve_workspaceQuery(request: WorkspaceQuery_Request): Promise<WorkspaceQuery_Response>;
}
export declare class Peer implements IPeer {
	peerId: PeerId;
	storageMap: SuperbusMap<WorkspaceAddress, IStorageAsync>;
	constructor();
	hasWorkspace(workspace: WorkspaceAddress): boolean;
	workspaces(): WorkspaceAddress[];
	storages(): IStorageAsync[];
	size(): number;
	getStorage(ws: WorkspaceAddress): IStorageAsync | undefined;
	addStorage(storage: IStorageAsync): Promise<void>;
	removeStorageByWorkspace(workspace: WorkspaceAddress): Promise<void>;
	removeStorage(storage: IStorageAsync): Promise<void>;
}
export declare type WillMatch = "all" | "all-latest" | "some" | "nothing";
export interface CleanUpQueryResult {
	query: Query;
	isValid: boolean;
	willMatch: WillMatch;
}
export declare let cleanUpQuery: (inputQuery: Query) => CleanUpQueryResult;
export declare let docMatchesFilter: (doc: Doc, filter: QueryFilter) => boolean;
export declare type QueryFollowerState = "new" | "catching-up" | "live" | "closed" | "error";
/**
 * Subscribe to the ongoing results of a query,
 * optionaly including old existing docs.
 * When anything happens, emit events on the queryFollower's bus.
 *
 * The bus subscriber callbacks are called blockingly, and so
 * each runs one at a time (one event at a time, and within
 * that event, one callback at a time).
 *
 * Subscribe to events on the bus, with bus.on(cb...).  You
 * will get LiveQueryEvent items, which include:
 *   - DocAlreadyExists -- processing an old doc as you catch up
 *   - IdleEvent -- reached the end of existing docs; waiting for new docs
 *   - IngestEvent
 *   -     IngestEventSuccess -- a new doc was written
 *   -     IngestEventFailure -- refused an invalid doc
 *   -     IngestEventNothingHappened -- ingested an obsolete or duplicate doc
 *   - StorageEventWillClose -- the storage is about to close
 *   - StorageEventDidClose -- the storage has closed
 *   - QueryFollowerDidClose -- the query follower was closed
 *                               (can happen on its own or after the storage closes)
 *
 * The query has some limitations:
 *   - historyMode must be 'all'
 *   - orderBy must be 'localIndex ASC'
 *   - limit cannot be set. (TODO: fix this eventually)
 *
 * The query's startAfter controls the behavior of the live query:
 *   - If startAfter is not set, we begin with the next write event that occurs, and ignore
 *      old/existing documents.
 *   - If startAfter is set to a localIndex value, begin there.  This may involve running
 *      through a backlog of existing documents, then eventually catching up and switching
 *      over to ingest events as new things happen.
 *      The usual use case for this is to set startAfter to localIndex: -1 to begin processing
 *      with the oldest doc (to get all of them).
 *
 *  So the liveQuery can be in two modes:
 *    1. catching up with the backlog
 *    2. caught up; processing new events as they happen.
 *
 * A QueryFollower has a "state" (a QueryFollowerState).
 * Read it with queryFollower.state().  You cannot set it.
 * It can be:
 *
 *  - new -- not running yet; you need to call "await hatch()"
 *  - catching-up -- hatch() has been called, we're catching up on old docs
 *  - live -- we're listening for new write events
 *  - closed -- the query follower is closed
 *  - error -- an unexpected error happened, maybe in your bus subscription handler
 *
 * You can manually close a query follower with close(), and it will also
 * automatically close if the storage closes.
 *
 * To use a QueryFollower, do this:
 *
 *     let qf = new QueryFollower(storage, your_query_here)
 *     qf.bus.on(async (event: LiveQueryEvent) => {
 *         // handle events here
 *         if (event.kind === 'existing' || event.kind === 'success') {
 *             // do something with event.doc
 *         }
 *     });
 *
 *     // after setting up your event handler...
 *     // start processing docs.
 *     await qf.hatch();
 *
 *     // eventually close the storage,
 *     // or at least close the query follower.
 *     // you don't need to do both.
 *     await qf.close();
 *
 * When the query follower is in catching-up mode, it runs independently
 * on its own schedule.  When it's in live mode, it processes each doc
 * as it's written, blockingly (because that's how the storage.bus events
 * work) which means it provides backpressure all the way back up to
 * whatever is trying to ingest() docs into the storage.
 *
 * There is not currently an easy way to know when a query follower has
 * caught up and switched to live mode, except to listen for the 'idle' event
 * on its bus.
 *
 * For now it's tricky to close a query follower from inside its own event handler;
 * you have to do it using setTimeout or you'll deadlock on the bus's lock.
 *      qf.bus.on(await (event) => {
 *          setTimeout(() => qf.close(), 0);
 *      });
 * (...because you can't send an event from inside an event handler)
 *
 */
export interface IQueryFollower {
	storage: IStorageAsync;
	query: Query;
	bus: Simplebus<LiveQueryEvent>;
	state(): QueryFollowerState;
	/**
	 * This begins the process of catching up (if needed), then
	 * switches to live mode.
	 */
	hatch(): Promise<void>;
	/**
	 * Shut down the QueryFollower; unhook from the Storage; process no more events.
	 * This is permanent.
	 * This happens when the storage closes (we've subscribed to storage willClose)
	 * and it can also be called manually if you just want to destroy this queryFollower.
	 */
	close(): Promise<void>;
}
export declare type Thunk = () => void;
export declare type Callback<T> = (data: T) => void;
export declare type AsyncCallback<T> = (data: T) => Promise<void>;
export declare type SyncOrAsyncCallback<T> = (data: T) => Promise<void> | void;
export declare type ClassThatImplements<T> = new (...args: any[]) => T;
export declare enum Cmp {
	LT = -1,
	EQ = 0,
	GT = 1
}
export declare class QueryFollower implements IQueryFollower {
	storage: IStorageAsync;
	query: Query;
	bus: Simplebus<LiveQueryEvent>;
	_state: QueryFollowerState;
	_unsub: Thunk | null;
	constructor(storage: IStorageAsync, query: Query);
	_expectState(states: QueryFollowerState[]): void;
	state(): QueryFollowerState;
	hatch(): Promise<void>;
	_catchUp(): Promise<void>;
	_subscribe(): void;
	close(): Promise<void>;
}
export declare type SortOrder = "ASC" | "DESC";
export declare let sortedInPlace: <T>(array: T[]) => T[];
export declare let compareBasic: (a: any, b: any, order?: SortOrder) => Cmp;
/**
 * example usage: myArrayOfArrays.sort(arrayCompare)
 *
 * Compare arrays element by element, stopping and returning the first non-EQ comparison.
 * Earlier array items are more important.
 * When arrays are different lengths and share the same prefix, the shorter one
 * is less than the longer one.  In other words, the undefined you would get by
 * reading of the end of the array counts as lower than any other value.
 *
 * For example, this list of arrays is sorted:
 *   - [1],
 *   - [1, 1],
 *   - [1, 1, 99],
 *   - [1, 2],
 *   - [1, 2],
 *   - [2],
 *   - [2, 99],
 *   - [2, 99, 1],
 *
 * sortOrders is an array of 'ASC' | 'DESC' strings.  Imagine it's applied
 * to the columns of a spreadsheet.
 *
 * For example, to sort DESC by the first item, and ASC by the second item:
 *  compareArrays(['hello', 123], ['goodbye', 456], ['DESC', 'ASC']).
 *
 * Sort order defaults to 'ASC' when the sortOrders array is not provided.
 * If the sortOrders array is shorter than the arrays to be sorted, it acts
 *  as if it was filled out with additional 'ASC' entries as needed.
 * A sort order of 'DESC' in the appropriate column can make longer arrays
 *  come before shorter arrays.
 *
 *  sortOrders ['ASC', 'DESC'] sorts in this order:
 *  - [1, 99],
 *  - [1, 2],
 *  - [1],  // shorter array comes last, because of DESC in this column
 *  - [2],  // but first element is still sorted ASC
 */
export declare let compareArrays: (a: any[], b: any[], sortOrders?: SortOrder[] | undefined) => Cmp;
export declare let compareByObjKey: (key: string, sortOrder?: SortOrder) => (a: Record<string, any>, b: Record<string, any>) => Cmp;
export declare let compareByFn: (fn: (x: any) => any) => (a: Record<string, any>, b: Record<string, any>) => Cmp;
export declare let compareByObjArrayFn: (fn: (x: any) => any[]) => (a: Record<string, any>, b: Record<string, any>) => Cmp;
export declare class StorageAsync implements IStorageAsync {
	storageId: StorageId;
	workspace: WorkspaceAddress;
	formatValidator: IFormatValidator;
	storageDriver: IStorageDriverAsync;
	bus: Superbus<StorageBusChannel>;
	_isClosed: boolean;
	_ingestLock: Lock<IngestEvent>;
	constructor(workspace: WorkspaceAddress, validator: IFormatValidator, driver: IStorageDriverAsync);
	isClosed(): boolean;
	close(erase: boolean): Promise<void>;
	getConfig(key: string): Promise<string | undefined>;
	setConfig(key: string, value: string): Promise<void>;
	listConfigKeys(): Promise<string[]>;
	deleteConfig(key: string): Promise<boolean>;
	getMaxLocalIndex(): number;
	getDocsAfterLocalIndex(historyMode: HistoryMode, startAfter: LocalIndex, limit?: number): Promise<Doc[]>;
	getAllDocs(): Promise<Doc[]>;
	getLatestDocs(): Promise<Doc[]>;
	getAllDocsAtPath(path: Path): Promise<Doc[]>;
	getLatestDocAtPath(path: Path): Promise<Doc | undefined>;
	queryDocs(query?: Query): Promise<Doc[]>;
	set(keypair: AuthorKeypair, docToSet: DocToSet): Promise<IngestEvent>;
	ingest(docToIngest: Doc): Promise<IngestEvent>;
	overwriteAllDocsByAuthor(keypair: AuthorKeypair): Promise<number | ValidationError>;
}
export declare class StorageCache {
	_storage: IStorageAsync;
	_docCache: Map<string, {
		docs: Doc[];
		follower: QueryFollower;
		expires: number;
	}>;
	_timeToLive: number;
	_onCacheUpdatedCallbacks: Set<() => void | (() => Promise<void>)>;
	constructor(storage: IStorageAsync, timeToLive?: number);
	getAllDocs(): Doc[];
	getLatestDocs(): Doc[];
	getAllDocsAtPath(path: Path): Doc[];
	getLatestDocAtPath(path: Path): Doc | undefined;
	queryDocs(query?: Query): Doc[];
	set(keypair: AuthorKeypair, docToSet: DocToSet): IngestEvent;
	overwriteAllDocsByAuthor(keypair: AuthorKeypair): Promise<number | ValidationError>;
	_updateCacheOptimistically(doc: Doc): void;
	_fireOnCacheUpdateds(): Promise<(void | (() => Promise<void>))[]>;
	onCacheUpdated(callback: () => void | (() => Promise<void>)): () => void;
}
export declare class StorageDriverAsyncMemory implements IStorageDriverAsync {
	workspace: WorkspaceAddress;
	_maxLocalIndex: LocalIndex;
	_isClosed: boolean;
	_configKv: Record<string, string>;
	docByPathAndAuthor: Map<string, Doc>;
	docsByPathNewestFirst: Map<Path, Doc[]>;
	constructor(workspace: WorkspaceAddress);
	isClosed(): boolean;
	close(erase: boolean): Promise<void>;
	getConfig(key: string): Promise<string | undefined>;
	setConfig(key: string, value: string): Promise<void>;
	listConfigKeys(): Promise<string[]>;
	deleteConfig(key: string): Promise<boolean>;
	getMaxLocalIndex(): number;
	_getAllDocs(): Promise<Doc[]>;
	_getLatestDocs(): Promise<Doc[]>;
	queryDocs(queryToClean: Query): Promise<Doc[]>;
	upsert(doc: Doc): Promise<Doc>;
}
/**
 * This file provides common operations on Buffer.
 * Any util function that uses a Buffer should be here, not in bytes.ts.
 */
export declare let bytesToBuffer: (bytes: Uint8Array) => Buffer;
export declare let bufferToBytes: (buf: Buffer) => Uint8Array;
export declare let stringToBuffer: (str: string) => Buffer;
export declare let bufferToString: (buf: Buffer) => string;
/**
 * This file provides common operations on Uint8Arrays.
 * It should not use any Buffers to do so.
 * Any function that uses Buffer should be in buffers.ts.
 * This helps us avoid bringing in the heavy polyfill for Buffer
 * when bundling for the browser.
 */
export declare let bytesToString: (bytes: Uint8Array) => string;
export declare let stringToBytes: (str: string) => Uint8Array;
export declare let stringLengthInBytes: (str: string) => number;
export declare let concatBytes: (a: Uint8Array, b: Uint8Array) => Uint8Array;
export declare let b64StringToBytes: (b64string: string) => Uint8Array;
export declare let hexStringToBytes: (hexString: string) => Uint8Array;
export declare let isBytes: (bytes: any) => bytes is Uint8Array;
export declare let isBuffer: (buf: any) => boolean;
export declare let identifyBufOrBytes: (bufOrBytes: Buffer | Uint8Array) => string;
/**
 * Logs are assigned a priority number.
 * Higher numbers are less important information.
 * Set your desired log level higher to get more info.
 *
 *  -1 nothing
 *   0 only errors
 *   1 also warnings
 *   2 also logs
 *   3 also debugs
 *
 * Logs also come from different "sources" which can
 * have different log level settings.
 *
 * Two ways to modify the log level settings:
 *
 * 1. Set an environment variable in the shell.
 *    This applies to all "sources" (can't be set individually)
 *         EARTHSTAR_LOG_LEVEL=2 npm run test
 *
 * 2. Use setLogLevels() to globally modify the levels:
 *         setLogLevels({ sync: 2 });
 *
 * The environment variable wins over the numbers set by setLogLevels.
 */
export declare type LogSource = string;
export declare enum LogLevel {
	None = -1,
	Error = 0,
	Warn = 1,
	Log = 2,
	Info = 3,
	Debug = 4
}
export declare const DEFAULT_LOG_LEVEL = LogLevel.Error;
export declare type LogLevels = Record<LogSource, LogLevel>;
export declare const updateLogLevels: (newLogLevels: LogLevels) => void;
export declare const setLogLevel: (source: LogSource, level: LogLevel) => void;
export declare const setDefaultLogLevel: (level: LogLevel) => void;
export declare const getLogLevel: (source: LogSource) => LogLevel;
export declare const getLogLevels: () => LogLevels;
export declare type ChalkColor = "blue" | "blueBright" | "bold" | "cyan" | "cyanBright" | "dim" | "gray" | "green" | "greenBright" | "grey" | "magenta" | "magentaBright" | "red" | "redBright" | "white" | "whiteBright" | "yellow" | "yellowBright";
export declare class Logger {
	source: LogSource;
	color: ChalkColor | undefined;
	constructor(source: LogSource, color?: ChalkColor);
	_print(level: LogLevel, showTag: boolean, indent: string, ...args: any[]): void;
	error(...args: any[]): void;
	warn(...args: any[]): void;
	log(...args: any[]): void;
	info(...args: any[]): void;
	debug(...args: any[]): void;
	blank(): void;
}
export declare let deepEqual: (a: any, b: any) => boolean;
export declare let deepCopy: <T>(input: T) => T;
export declare let microsecondNow: () => number;
export declare let sleep: (ms: number) => Promise<unknown>;
export declare let randomId: () => string;
/**
 * A verison of the ILowLevelCrypto interface backed by native Node crypto functions.
 * Requires a recent version of Node, perhaps 12+?
 * Does not work in the browser.
 */
export declare const CryptoDriverNode: ICryptoDriver;

export {};
